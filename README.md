# IBM-Project-13848-1659533086
A Gesture-based Tool for Sterile Browsing of Radiology Images

# A Gesture-Based Tool For Sterile Browsing Of Radiology Images
Humans are able to recognize body and sign language easily. 
This is possible due to the combination of vision and synaptic interactions that were formed along brain development . 
In order to replicate this skill in computers, some problems need to be solved: 
  - how to separate objects of interest in images and which image capture technology and classification technique are more appropriate, among others.


In this project Gesture based Desktop automation ,First the model is trained pre trained on the images of different hand gestures, such as a showing numbers with fingers as 1 ,2,3,4 . 
This model uses the integrated webcam to capture the video frame. The image of the gesture captured in the video frame is compared with  the Pre-trained model and the gesture is identified. 
If the gesture predictes is 1 then images is blurred;2, image is resized;3,image is rotated etc.



Technical Architecture:

![image3](https://user-images.githubusercontent.com/73353391/190845405-b7f6d010-e9f5-4cbc-b2af-b2ec230cc567.png)
